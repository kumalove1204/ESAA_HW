{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10/11제출필사-사이킷런.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyONv7j7zAjaa3ujwY6rcwyI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumalove1204/ESAA_HW/blob/main/10_11%EC%A0%9C%EC%B6%9C%ED%95%84%EC%82%AC_%EC%82%AC%EC%9D%B4%ED%82%B7%EB%9F%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEKbszT_j3Wj"
      },
      "source": [
        "\n",
        "## **사이킷런 소개와 특징**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7ErygCtj1IV",
        "outputId": "5f49fcdf-3160-4e7d-d7da-5a1ea44dfc06"
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.22.2.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1aWJ1hmkQLU"
      },
      "source": [
        "붓꽃 품종 예측하기 - 붓꽃 데이터 세트로 붓꽃의 품종을 분류\n",
        "\n",
        "붓꽃 데이터 세트의 꽃잎의 길이와 너비, 꽃받침의 길이와 너비 피처를 기반으로, 꽃의 품종을 예측해보자.\n",
        "\n",
        "분류: 대표적인 지도학습 방법의 하나\n",
        "\n",
        "지도학습: 명확한 정답이 주어진 데이터를 먼저 학습한 뒤 미지의 정답을 예측하는 방식"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKVEatLHkmpJ"
      },
      "source": [
        "from sklearn.datasets import load_iris   ## 제공되는 데이터셋에서 붓꽃데이터 추출\n",
        "from sklearn.tree import DecisionTreeClassifier   ##의사결정트리\n",
        "from sklearn.model_selection import train_test_split  ##학습 데이터와 테스트 데이터를 분리"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9q_TteWHkyDs"
      },
      "source": [
        "\n",
        "load_iris()함수를 이용해 붓꽃 데이터 세트를 로딩한 후, 피처들과 데이터 값이 어떻게 구성돼 있는지 확인하기 위해 DataFrame으로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "Degwvmh0kyx_",
        "outputId": "d018c0ed-15eb-408b-a11a-70f88f90aaf6"
      },
      "source": [
        "import pandas as pd\n",
        "iris=load_iris()\n",
        "\n",
        "#iris.data는 Iris 데이터 세트에서 피처만으로 된 데이터를 numpy로 가지고 있다\n",
        "iris_data=iris.data\n",
        "\n",
        "#iris.target은 붓꽃 데이터 세트에서 레이블(결정값) 데이터를 numpy로 가지고 있다\n",
        "iris_label=iris.target\n",
        "print('iris target값:', iris_label)\n",
        "print('iris target명', iris.target_names)\n",
        "\n",
        "#붓꽃 데이터 세트를 자세히 보기 위해 DataFrame으로 변환\n",
        "iris_df=pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
        "iris_df['label']=iris.target\n",
        "iris_df.head(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iris target값: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "iris target명 ['setosa' 'versicolor' 'virginica']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  ...  petal width (cm)  label\n",
              "0                5.1               3.5  ...               0.2      0\n",
              "1                4.9               3.0  ...               0.2      0\n",
              "2                4.7               3.2  ...               0.2      0\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wSBqsqxk1-f"
      },
      "source": [
        "0이 setosa 품종, 1이 versicolor 품종, 2가 virginica 품종을 의미"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q03GsIOYk65n"
      },
      "source": [
        "## **학습용 데이터와 테스트용 데이터를 분리**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtkIgOfNliAc"
      },
      "source": [
        "학습데이터로 학습된 모델이 얼마나 뛰어난 성능을 가지는 지 평가하려면 테스트 데이터세트가 필요하기 때문에 학습용 데이터와 테스트용 데이터는 반드시 분리해야 한다.\n",
        "\n",
        "→ sklearn은 train_test_split() API를 제공\n",
        "\n",
        "이를 이용하면 학습 데이터와 테스트 데이터를 test_size 파라미터 입력 값의 비율로 쉽게 분할할 수 있다.\n",
        "\n",
        "예를 들어 test_size=0.2로 입력 파라미터를 설정하면, 전체 데이터 중 테스트 데이터가 20%, 학습 데이터가 80%로 데이터를 분할한다.\n",
        "\n",
        "먼저 train_test_split()을 호출한 후 좀 더 자세히 입력 파라미터와 반환값을 알아보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwn6r8fBle2E"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)\n",
        "# random_state는 데이터 분할시 셔플이 이루어지는데 이를 위한 시드값\n",
        "# random_state 지정하지 않으면 수행할 때마다 다른 학습/테스트용 데이터가 만들어짐\n",
        "# 지금은 일정한 수 넣어 수행할 때마다 동일한 데이터 세트로 분리하기 위함\n",
        "# iris_data는 피처 데이터 세트, iris_label은 레이블 데이터 세트"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WQrR8TjmDqH",
        "outputId": "1500ac2f-e585-49ed-f225-1c5dafdaa49c"
      },
      "source": [
        "# DecisionTreeClassifier 객체 생성\n",
        "dt_clf=DecisionTreeClassifier(random_state=11)\n",
        "# 학습 수행\n",
        "dt_clf.fit(X_train, y_train)\n",
        "# 수행하면 Decision 객체는 학습 데이터를 기반으로 학습이 완료된 것"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=11, splitter='best')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORD4DPpUmN2j"
      },
      "source": [
        "# 학습이 완료된 Decision 객체에서 테스트 데이터 세트로 예측 수행\n",
        "pred=dt_clf.predict(X_test)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypb3GJkJmX8u"
      },
      "source": [
        "Descision의 예측 성능을 평가해 봐야 함.\n",
        "\n",
        "정확도 : 예측 결과가 실제 레이블 값과 얼마나 정확하게 맞는지를 평가하는 지표\n",
        "\n",
        "예측한 붓꽃 품종과 실제 데이터 세트의 붓꽃 품종이 얼마나 일치하는지 확인해보자.\n",
        "\n",
        "사이킷런은 정확도 측정을 위해 accuracy_score()함수를 제공\n",
        "\n",
        "accuracy_score()의 첫 번째 파라미터: 실제 레이블 데이터 세트\n",
        "\n",
        "accuracy_score()의 두 번째 파라미터: 예측 레이블 데이터 세트\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJJOZChfmU0_",
        "outputId": "263a4ebb-1b01-4eca-9343-cd2ae8201057"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도: 0.9333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xLGyN96m3AE"
      },
      "source": [
        "\n",
        "예측 프로세스를 요약하면 다음과 같다.\n",
        "\n",
        "1. 데이터 세트 분리: 데이터를 학습 데이터와 테스트 데이터로 분리\n",
        "\n",
        "2. 모델 학습: 학습 데이터를 기반으로 ML 알고리즘을 적용해 모델을 학습시킴\n",
        "\n",
        "3. 예측 수행: 학습된 ML 모델을 이용해 테스트 데이터의 분류(즉, 붓꽃 종류)를 예측\n",
        "\n",
        "4. 평가: 이렇게 예측된 결괏값과 테스트 데이터의 실제 결괏값을 비교해 ML 모델 성능을 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOFV9nfHnEXW"
      },
      "source": [
        "## **사이킷런의 기반 프레임워크 익히기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaLyVg_7nM9Q"
      },
      "source": [
        "\n",
        "Estimator 이해 및 fit(), predict() 메서드\n",
        "\n",
        "사이킷런은 ML 모델 학습을 위해서 fit()을, 학습된 모델의 예측을 위해 predict() 메서드를 제공\n",
        "\n",
        "지도학습의 주요 두 축인 분류와 회귀의 다양한 알고리즘을 구현한 모든 사이킷런 클래스는 fit과 predict 만 이용해 간단하게 학습과 예측 결과를 반환\n",
        "\n",
        "분류 알고리즘을 구현한 클래스를 Classifier로, 그리고 회귀 알고리즘을 구현한 클래스를 Regressor로 지칭 합쳐서 Estimator라고 부름\n",
        "\n",
        "cross_val_score() : 평가하거나 파라미터 튜닝 수행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaojTOeCnV-P"
      },
      "source": [
        "**비지도 학습**(차원 축소, 클러스터링, 피처 추출)과 **피처 추출**에서 **fit()**\n",
        "\n",
        ": 지도학습의 fit()과 같이 학습을 의미하는 게 아니라, **입력 데이터의 형태에 맞춰 데이터를 변환하기 위한 사전 구조를 맞추는 작업**\n",
        "\n",
        "피처 추출 등의 실제 작업은 transform()으로 수행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDHDdo46oOOU"
      },
      "source": [
        "사이킷런의 주요 모듈 sklearn.preprocessing (피처 처리) : 데이터 전처리에 필요한 가공 기능 제공(문자열을 숫자로 인코딩, 정규화 스케일링 등)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX5LO7QJno-n"
      },
      "source": [
        "sklearn.feature_selection (피처처리) : 알고리즘에 큰 영향을 미치는 피처를 우선순위대로 셀렉션 작업을 수행하는 기능 제공\n",
        "\n",
        "sklearn.feature_extraction(피처처리) : 텍스트 데이터나 이미지 데이터의 벡터화된 피처를 추출하는데 사용\n",
        "\n",
        "sklearn.decomposition (피처처리&차원축소) : 차원 축소와 관련한 알고리즘을 지원\n",
        "\n",
        "sklearn.model_selection(데이터 분리검증, 파라미터 튜닝) :교차 검증을 위한 학습용/테스트용 분리, 그리드 서치로 최적 파라미털 추출\n",
        "\n",
        "sklearn.metrics(평가) : 분류,회귀,클러스터링,페어와이즈에 대한 다양한 성능 측정 방법 제공\n",
        "\n",
        "sklearn.ensemble(ML알고리즘) : 앙상블 알고리즘 제공, 랜덤 포레스트, 에이다 부스트, 그래디언트 부승팅 등 제공\n",
        "\n",
        "sklearn.linear_model(ML알고리즘) : 선형 회귀, 릿지, 라쏘 및 로지스틱 회귀등 관련 알고리즘 지원, SGD도 지원\n",
        "\n",
        "sklearn.naive_bayes(ML알고리즘) : 나이브 베이즈 알고리즘 제공, 가우시안, 다항분포 NB등\n",
        "\n",
        "sklearn.neighbors(ML알고리즘) : 최근접 이웃 알고리즘 제공\n",
        "\n",
        "sklearn.tree(ML알고리즘) : 의사 결정 트리 알고리즘 제공\n",
        "\n",
        "sklearn.cluster(ML알고리즘) : 비지도 클러스터링 알고리즘 제공\n",
        "\n",
        "sklearn.pipeline(유틸리티) : 피처 처리 등의 변환과 ML 알고리즘 학습, 예측 등을 함께 묶어서 실행할수 있는 유틸리티 제공"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cxhl-nfyoX62",
        "outputId": "aa25f735-bb29-4751-e167-d3172d7353fe"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data=load_iris()\n",
        "print(type(iris_data))\n",
        "# load_iris() API 반환 결과 보여줌, 딕셔너리 형태임"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.utils.Bunch'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgpBSyBhoebL",
        "outputId": "a0de6819-ba55-4775-c64e-abff2a2865ff"
      },
      "source": [
        "keys=iris_data.keys()\n",
        "print('붓꽃 데이터 세트의 키들:', keys)\n",
        "# 데이터 키는 피처들의 데이터 값을 가리킴,\n",
        "# 딕셔너리 형태이므로 데이터 값 추출하기 위한 것"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "붓꽃 데이터 세트의 키들: dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xWzaJB4rQO5",
        "outputId": "8e0aa7a1-8d3f-4b52-87f4-1a887a3c79f6"
      },
      "source": [
        "#load_iris()가 반환하는 객체의 키인 features_names, target_name, data, target이 가리키는 값을 출력\n",
        "print('\\n feature_names 의 type:', type(iris_data.feature_names))\n",
        "print('feature_names 의 shape:', len(iris_data.feature_names))\n",
        "print('\\n target_names의 type:', type(iris_data.target_names))\n",
        "print('target_names의 shape:', type(iris_data.target_names))\n",
        "print(iris_data.target_names)\n",
        "\n",
        "print('\\n data의 type:', type(iris_data.data))\n",
        "print(\"data의 shape:\", iris_data.data.shape)\n",
        "print(iris_data['data'])\n",
        "\n",
        "print('\\n target의 type:', type(iris_data.target))\n",
        "print('target의 shape:', iris_data.target.shape)\n",
        "print(iris_data.target)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " feature_names 의 type: <class 'list'>\n",
            "feature_names 의 shape: 4\n",
            "\n",
            " target_names의 type: <class 'numpy.ndarray'>\n",
            "target_names의 shape: <class 'numpy.ndarray'>\n",
            "['setosa' 'versicolor' 'virginica']\n",
            "\n",
            " data의 type: <class 'numpy.ndarray'>\n",
            "data의 shape: (150, 4)\n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n",
            "\n",
            " target의 type: <class 'numpy.ndarray'>\n",
            "target의 shape: (150,)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfOZIfqorVUm",
        "outputId": "3157ec3b-a222-45ac-c882-8da3833bbb57"
      },
      "source": [
        "#학습/테스트 데이터 세트 분리 - train_test_split()\n",
        "#(먼저 테스트 데이터 세트를 이용하지 않고 학습 데이터 세트로만 학습하고 예측하면 무엇이 문제인지 살펴볼 것)\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris=load_iris()\n",
        "dt_clf=DecisionTreeClassifier()\n",
        "train_data=iris.data\n",
        "train_label=iris.target\n",
        "dt_clf.fit(train_data, train_label)\n",
        "\n",
        "# 학습 데이터 세트로 예측 수행\n",
        "pred=dt_clf.predict(train_data)\n",
        "print('예측 정확도:', accuracy_score(train_label, pred))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH6e-OcZrYjy"
      },
      "source": [
        "예측 정확도: 1.0\n",
        "\n",
        "예측결과과 100 정확한 이유는 이미 학습한 학습 데이터 세트를 기반으로 예측해서임\n",
        "\n",
        "예측을 수행하는 데이터 세트는 학습용 데이터 세트가 아닌 전용의 테스트 데이터 세트여야 함\n",
        "\n",
        "train_test_split()를 통해 원본 데이터 세트에서 학습 및 테스트 데이터세트를 분리\n",
        "\n",
        "반환값은 튜플형식, 순차적으로 학습용 데이터의 피처, 테스트용 피처, 학습용 데이터의 레이블, 테스트용 레이더의 레이블 반환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bVYnVcvrb4x",
        "outputId": "27b0dd44-fc23-45bd-de85-dac74595b8d3"
      },
      "source": [
        "dt_clf.fit(X_train, y_train)\n",
        "pred=dt_clf.predict(X_test)\n",
        "print(\"예측 정확도 : {0:.4f}\".format(accuracy_score(y_test, pred)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도 : 0.9333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L0CFLTDremf",
        "outputId": "f4a176c6-4b9f-4790-f140-074453d445f3"
      },
      "source": [
        "## 교차 검증-본고사 치르기 전에 모의고사 여러번 보기\n",
        "## 1)K 폴드 교차 검증 - 먼저 K개의 데이터 폴드 세트를 만들어서 K번만큼 각 폴트 세트에 학습과 검증 평가를 반복적 수행\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "iris=load_iris()\n",
        "features = iris.data\n",
        "label=iris.target\n",
        "dt_clf=DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
        "kfold=KFold(n_splits=5)\n",
        "cv_accuracy = []\n",
        "print('붓꽃 데이터 세트 크기:',features.shape[0])\n",
        "\n",
        "## KFold 객체를 생성했으니 객체의 split()을 호출해 전체 붓꽃 데이터를 5개의 폴드 데이터 세트로 분리\n",
        "## 전체 붓꽃데이터는 모두 150개, 따라서 학습용 데이터 세트는 이중 4/5인 120개, 검증 데이터 세트는 1/5인 3-개로 분할"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "붓꽃 데이터 세트 크기: 150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku7sBdK_rhYz",
        "outputId": "7c2d3ecf-f19e-4b3f-d3e5-a30e6c5c01e3"
      },
      "source": [
        "n_iter = 0\n",
        "\n",
        "# KFold 객체의 split()를 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환\n",
        "for train_index, test_index in kfold.split(features):\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "#학습 및 예측\n",
        "    dt_clf.fit(X_train, y_train)\n",
        "    pred=dt_clf.predict(X_test)\n",
        "    n_iter+=1\n",
        "# 반복 시마다 정확도 측정\n",
        "    accuracy = np.round(accuracy_score(y_test, pred),4)\n",
        "    train_size=X_train.shape[0]\n",
        "    test_size=X_test.shape[0]\n",
        "    print('\\n#[0] 교차 검증 정확도 : {1}, 학습 데이터 크기: {2}, 검증 데이터 크기:{3}'.format(n_iter,accuracy,train_size, test_size)) \n",
        "    print('{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
        "    cv_accuracy.append(accuracy)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#[0] 교차 검증 정확도 : 1.0, 학습 데이터 크기: 120, 검증 데이터 크기:30\n",
            "1 검증 세트 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "\n",
            "#[0] 교차 검증 정확도 : 0.9667, 학습 데이터 크기: 120, 검증 데이터 크기:30\n",
            "2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
            " 54 55 56 57 58 59]\n",
            "\n",
            "#[0] 교차 검증 정확도 : 0.8667, 학습 데이터 크기: 120, 검증 데이터 크기:30\n",
            "3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
            " 84 85 86 87 88 89]\n",
            "\n",
            "#[0] 교차 검증 정확도 : 0.9333, 학습 데이터 크기: 120, 검증 데이터 크기:30\n",
            "4 검증 세트 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
            "\n",
            "#[0] 교차 검증 정확도 : 0.7333, 학습 데이터 크기: 120, 검증 데이터 크기:30\n",
            "5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
            " 138 139 140 141 142 143 144 145 146 147 148 149]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIGoLyZlrj4q",
        "outputId": "3b55b14a-f0b6-4ff6-c188-36b8bbc4c772"
      },
      "source": [
        "## 개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
        "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "## 평균 검증 정확도: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwWthjetrmtv"
      },
      "source": [
        "# 2) Stratified K 폴드\n",
        "\n",
        ": 불균형한 분포도를 가진 레이블 데이터를 위한 기법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNSvWuvqrrd0",
        "outputId": "a9ad77c8-3cfe-4603-c32f-0f909054c56f"
      },
      "source": [
        "# 분포도를 확인\n",
        "import pandas as pd\n",
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "iris_df['label'].value_counts()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    50\n",
              "1    50\n",
              "0    50\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S07Y1CigruOE",
        "outputId": "4f4e7f60-ec52-4d5c-a315-f8495c83f92c"
      },
      "source": [
        "kfold = KFold(n_splits=3)\n",
        "n_iter = 0\n",
        "for train_index, test_index in kfold.split(iris_df):\n",
        "    n_iter+=1\n",
        "    label_train=iris_df['label'].iloc[train_index]\n",
        "    label_test=iris_df['label'].iloc[test_index]\n",
        "    print('##교차 검증: {0}'.format(n_iter))\n",
        "    print(\"학습 레이블 데이터 분포:\\n\", label_train.value_counts())\n",
        "    print(\"검증 레이블 데이터 분포:\\n\", label_test.value_counts())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##교차 검증: 1\n",
            "학습 레이블 데이터 분포:\n",
            " 2    50\n",
            "1    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 0    50\n",
            "Name: label, dtype: int64\n",
            "##교차 검증: 2\n",
            "학습 레이블 데이터 분포:\n",
            " 2    50\n",
            "0    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 1    50\n",
            "Name: label, dtype: int64\n",
            "##교차 검증: 3\n",
            "학습 레이블 데이터 분포:\n",
            " 1    50\n",
            "0    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    50\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}